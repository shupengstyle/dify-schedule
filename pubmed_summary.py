import os
import time
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from Bio import Entrez
from bs4 import BeautifulSoup
import requests
import logging
import dotenv
import json
from datetime import datetime, timedelta
import openai
import google.generativeai as genai  # å¯¼å…¥ Gemini API

# Load environment variables from .env file
dotenv.load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ç¯å¢ƒå˜é‡é…ç½®
PUBMED_API_KEY = os.getenv("PUBMED_API_KEY")
EMAIL_ADDRESS = os.getenv("EMAIL_ADDRESS")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
SMTP_SERVER = os.getenv("EMAIL_SMTP_SERVER", "smtp.yeah.net")
SMTP_PORT = int(os.getenv("EMAIL_SMTP_PORT", 465))
SEARCH_QUERY = os.getenv("SEARCH_QUERY")
MAX_RESULTS = int(os.getenv("MAX_RESULTS", 5))
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # æ–°å¢: Gemini API Key
SUMMARY_LANGUAGE = os.getenv("SUMMARY_LANGUAGE", "en")
PROCESSED_PMIDS_FILE = os.getenv("PROCESSED_PMIDS_FILE", "processed_pmids.json")
PROCESSED_PMIDS_EXPIRATION_DAYS = int(os.getenv("PROCESSED_PMIDS_EXPIRATION_DAYS", 30))

# åˆå§‹åŒ–é…ç½®
Entrez.email = EMAIL_ADDRESS
Entrez.api_key = PUBMED_API_KEY

# åˆå§‹åŒ– DeepSeek API å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)

# åˆå§‹åŒ– Gemini API å®¢æˆ·ç«¯
genai.configure(api_key=GEMINI_API_KEY)
gemini_model = genai.GenerativeModel('gemini-pro')  # é€‰æ‹©åˆé€‚çš„ Gemini æ¨¡å‹


def load_processed_pmids():
    """Load processed PMIDs from file."""
    try:
        with open(PROCESSED_PMIDS_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except json.JSONDecodeError:  # Handle corrupted JSON file
        logging.warning("Processed PMIDs file is corrupted. Starting with an empty list.")
        return []


def save_processed_pmids(pmids):
    """Save processed PMIDs to file."""
    try:
        with open(PROCESSED_PMIDS_FILE, "w") as f:
            json.dump(pmids, f)
    except Exception as e:
        logging.error(f"Failed to save processed PMIDs to file: {e}")


def fetch_articles():
    """è·å–æ–‡çŒ®åˆ—è¡¨å’ŒåŸºæœ¬ä¿¡æ¯"""
    try:
        handle = Entrez.esearch(
            db="pubmed",
            term=SEARCH_QUERY,
            retmax=MAX_RESULTS,
            sort="pub_date",
            usehistory="y"
        )
        result = Entrez.read(handle)
        id_list = result["IdList"]

        # Fetch article details in batch
        handle = Entrez.efetch(db="pubmed", id=",".join(id_list), rettype="xml", retmode="text")
        xml_data = handle.read()
        soup = BeautifulSoup(xml_data, "lxml-xml")

        articles = []
        for article in soup.find_all("PubmedArticle"):
            try:
                pmid = article.find("PMID").get_text()
                title = article.find("ArticleTitle").get_text() if article.find("ArticleTitle") else "æ— æ ‡é¢˜"
                journal = article.find("ISOAbbreviation").get_text() if article.find("ISOAbbreviation") else "æœªçŸ¥æ‚å¿—"
                year = article.find("Year").get_text() if article.find("Year") else "æœªçŸ¥å¹´ä»½"
                doi = article.find("ELocationID", {"EIdType": "doi"}).get_text() if article.find("ELocationID", {"EIdType": "doi"}) else "æ— DOI"
                pmcid = article.find("ArticleId", {"IdType": "pmc"}).get_text() if article.find("ArticleId", {"IdType": "pmc"}) else "æ— PMCID"

                # å¤„ç†ä½œè€…ä¿¡æ¯
                authors = []
                for author in article.find_all("Author"):
                    lastname = author.find("LastName").get_text() if author.find("LastName") else ""
                    initials = author.find("Initials").get_text() if author.find("Initials") else ""
                    if lastname and initials:
                        authors.append(f"{lastname} {initials}")

                # å¤„ç†æ‘˜è¦
                abstract = ""
                if abstract_section := article.find("Abstract"):
                    abstract = "\n".join([text.get_text() for text in abstract_section.find_all("AbstractText")])

                articles.append({
                    "pmid": pmid,
                    "title": title,
                    "journal": journal,
                    "year": year,
                    "doi": doi,
                    "pmcid": pmcid,
                    "authors": authors,
                    "abstract": abstract
                })
            except Exception as e:
                logging.error(f"è§£æPMID {pmid} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ç« 

        return articles

    except Exception as e:
        logging.error(f"æ–‡çŒ®æœç´¢å¤±è´¥: {str(e)}")
        return []


def get_fulltext_by_doi(doi):
    """å°è¯•é€šè¿‡DOIè·å–å…¨æ–‡"""
    if doi == "æ— DOI":
        return None

    try:
        url = f"https://doi.org/{doi}"
        response = requests.get(url, headers={"Accept": "text/plain"}, timeout=10)
        if response.status_code == 200:
            return response.text
        else:
            print(f"é€šè¿‡DOIè·å–å…¨æ–‡å¤±è´¥ (Status Code: {response.status_code}), doi: {doi}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚DOIå…¨æ–‡å¤±è´¥: {str(e)}, doi: {doi}")
        return None


def get_fulltext_by_pmcid(pmcid):
    """å°è¯•é€šè¿‡PMCIDè·å–å…¨æ–‡"""
    if not pmcid or pmcid == "æ— PMCID":
        return None

    try:
        url = f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmcid}/?format=txt"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            return response.text
        else:
            print(f"é€šè¿‡PMCIDè·å–å…¨æ–‡å¤±è´¥ (Status Code: {response.status_code}), pmcid: {pmcid}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚PMCIDå…¨æ–‡å¤±è´¥: {str(e)}, pmcid: {pmcid}")
        return None


def translate_text(text, target_language="zh-CN"):
    """ä½¿ç”¨ DeepSeek API ç¿»è¯‘æ–‡æœ¬, å¤±è´¥åˆ™ä½¿ç”¨ Gemini API"""
    if not text:
        return ""
    try:
        prompt = f"Translate the following text to {target_language}: {text}"
        response = client.chat.completions.create(
            model="deepseek-chat",  # æˆ–è€…é€‰æ‹©å…¶ä»–é€‚åˆç¿»è¯‘çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in translating scientific articles."},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content.strip() if response.choices else text
    except Exception as e:
        logging.error(f"DeepSeek API ç¿»è¯‘å¤±è´¥: {str(e)}, å°è¯•ä½¿ç”¨ Gemini API")
        return translate_text_gemini(text, target_language)  # è°ƒç”¨ Gemini API


def summarize_text(text, target_language="en"):
    """ä½¿ç”¨ DeepSeek API ç”Ÿæˆæ–‡æœ¬æ€»ç»“, å¤±è´¥åˆ™ä½¿ç”¨ Gemini API"""
    if not text:
        return "æ— å†…å®¹å¯æ€»ç»“"
    try:
        prompt = f"""
        Please provide an academic summary of the following medical research article, 
        ensuring it encompasses the study's background, the methodology used, 
        the principal research results obtained, and an assessment of the research's significance and value. 
        The summary should be clear, concise, and free of unnecessary detail. 
        æ–‡æœ¬ï¼š
        {text}
        """
        response = client.chat.completions.create(
            model="deepseek-chat",  # æˆ–è€…é€‰æ‹©å…¶ä»–é€‚åˆæ‘˜è¦çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in summarizing scientific articles."},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        # æ¸…ç† DeepSeek API è¿”å›çš„æ–‡æœ¬
        summary = response.choices[0].message.content.strip() if response.choices else "æ— æ³•ç”Ÿæˆæ€»ç»“"
        cleaned_text = summary.replace("**", "").replace("*", "", ).replace("â– ", "").replace("â—", "").replace("â—†", "")
        return cleaned_text
    except Exception as e:
        logging.error(f"DeepSeek API æ€»ç»“å¤±è´¥: {str(e)}, å°è¯•ä½¿ç”¨ Gemini API")
        return summarize_text_gemini(text, target_language)  # è°ƒç”¨ Gemini API


def translate_text_gemini(text, target_language="zh-CN"):
    """ä½¿ç”¨ Gemini API ç¿»è¯‘æ–‡æœ¬"""
    if not text:
        return ""
    try:
        prompt = f"Translate the following text to {target_language}: {text}"
        response = gemini_model.generate_content(prompt)
        return response.text.strip() if response.text else text
    except Exception as e:
        logging.error(f"Gemini API ç¿»è¯‘å¤±è´¥: {str(e)}")
        return text


def summarize_text_gemini(text, target_language="en"):
    """ä½¿ç”¨ Gemini API ç”Ÿæˆæ–‡æœ¬æ€»ç»“"""
    if not text:
        return "æ— å†…å®¹å¯æ€»ç»“"
    try:
        prompt = f"""
        Please provide an academic summary of the following medical research article, 
        ensuring it encompasses the study's background, the methodology used, 
        the principal research results obtained, and an assessment of the research's significance and value. 
        The summary should be clear, concise, and free of unnecessary detail. 
        æ–‡æœ¬ï¼š
        {text}
        """
        response = gemini_model.generate_content(prompt)
        return response.text.strip() if response.text else "æ— æ³•ç”Ÿæˆæ€»ç»“"
    except Exception as e:
        logging.error(f"Gemini API æ€»ç»“å¤±è´¥: {str(e)}")
        return "æ— æ³•ç”Ÿæˆæ€»ç»“"


def cleanup_processed_pmids(pmids):
    """Cleanup processed PMIDs, removing entries older than PROCESSED_PMIDS_EXPIRATION_DAYS."""
    cutoff_date = datetime.now() - timedelta(days=PROCESSED_PMIDS_EXPIRATION_DAYS)
    cleaned_pmids = []
    for entry in pmids:
        try:
            # Assuming the timestamp is stored as a string in ISO format
            entry_date = datetime.fromisoformat(entry["timestamp"])
            if entry_date >= cutoff_date:
                cleaned_pmids.append(entry)
        except (KeyError, ValueError) as e:
            logging.warning(f"Invalid entry format in processed PMIDs: {entry}. Error: {e}. Skipping.")
            continue  # Skip invalid entries
    logging.info(f"Cleaned up processed PMIDs, removed {len(pmids) - len(cleaned_pmids)} entries.")
    return cleaned_pmids


def send_email(articles):
    """å‘é€æ–‡çŒ®æ±‡æ€»é‚®ä»¶"""
    try:
        # æ„å»ºé‚®ä»¶å†…å®¹
        msg = MIMEMultipart()
        msg["From"] = EMAIL_ADDRESS
        msg["To"] = EMAIL_ADDRESS
        msg["Subject"] = f"PubMedæ–‡çŒ®æ›´æ–° - {SEARCH_QUERY}"

        # HTMLå†…å®¹æ¨¡æ¿
        html_content = f"""
        <html>
            <body>
                <h2>æœ€æ–° {len(articles)} ç¯‡æ–‡çŒ®</h2>
                <p>æœç´¢å…³é”®è¯: {SEARCH_QUERY}</p>
        """

        for idx, article in enumerate(articles, 1):
            html_content += f"""
            <div style="margin-bottom: 30px; border-bottom: 1px solid #eee;">
                <h3>{idx}. {article['title']}</h3>
                 <p><b>ä¸­æ–‡æ ‡é¢˜:</b> {article['translated_title']}</p>
                <p><b>ä½œè€…:</b> {', '.join(article['authors'])}</p>
                <p><b>æœŸåˆŠ:</b> {article['journal']} ({article['year']})</p>
                <p><b>ä¸­æ–‡æ€»ç»“:</b><br>{article['summary']}</p>
                <p>
                    <a href="{article['link']}">PubMedé“¾æ¥</a> |
                    <a href="https://doi.org/{article['doi']}">å…¨æ–‡é“¾æ¥</a>
                </p>
            </div>
            """

        html_content += "</body></html>"
        msg.attach(MIMEText(html_content, "html", "utf-8"))

        # å‘é€é‚®ä»¶
        try:
            logging.info(f"Connecting to SMTP server: {SMTP_SERVER}:{SMTP_PORT}")
            with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:
                logging.info(f"Logging in to email account: {EMAIL_ADDRESS}")
                server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
                logging.info("Login successful.")
                logging.info(f"Sending email to: {EMAIL_ADDRESS}")
                server.send_message(msg)
                logging.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
        except smtplib.SMTPException as e:
            logging.error(f"âŒ SMTP error occurred: {e}")
            raise  # Re-raise the exception to be caught in the outer block

    except Exception as e:
        logging.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")


def is_processed(processed_pmids, article):
    """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²è¢«å¤„ç†ï¼Œä¼˜å…ˆä½¿ç”¨PMCIDï¼Œå¦‚æœPMCIDä¸å­˜åœ¨åˆ™ä½¿ç”¨DOI"""
    for entry in processed_pmids:
        if article["pmcid"] != "æ— PMCID" and entry.get("pmcid") == article["pmcid"]:  # ä¼˜å…ˆåŒ¹é…PMCID
            return True
        elif article["doi"] != "æ— DOI" and entry.get("doi") == article["doi"]:  # å¦‚æœæ²¡æœ‰PMCIDï¼Œåˆ™åŒ¹é…DOI
            return True
    return False


if __name__ == "__main__":
    logging.info("ğŸš€ å¼€å§‹è·å–æ–‡çŒ®...")
    all_articles = fetch_articles()

    if not all_articles:
        logging.warning("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®")
        exit()

    processed_pmids = load_processed_pmids()
    processed_pmids = cleanup_processed_pmids(processed_pmids)

    new_articles = []

    for article in all_articles:
        if not is_processed(processed_pmids, article):
            # è·å–å…¨æ–‡
            fulltext = get_fulltext_by_doi(article["doi"])
            if not fulltext:
                fulltext = get_fulltext_by_pmcid(article["pmcid"])

            # æ€»ç»“å’Œç¿»è¯‘
            if fulltext:
                summary = summarize_text(fulltext)
            else:
                summary = summarize_text(article["abstract"] or "æ— æ‘˜è¦")

            translated_summary = translate_text(summary, target_language="zh-CN")
            translated_title = translate_text(article["title"], target_language="zh-CN")

            # å°†ç»“æœæ·»åŠ åˆ° new_articles
            article["summary"] = translated_summary
            article["translated_title"] = translated_title
            article["link"] = f"https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/"
            new_articles.append(article)

            # ä¿å­˜å·²å¤„ç†çš„ PMID ä¿¡æ¯
            processed_pmids.append({
                "pmid": article["pmid"],
                "timestamp": datetime.now().isoformat(),
                "pmcid": article["pmcid"],
                "doi": article["doi"]
            })
            logging.info(f"å·²æ·»åŠ æ–°æ–‡ç« : PMID {article['pmid']}, æ ‡é¢˜: {article['title']}")
            time.sleep(0.5)  # é¿å…é€Ÿç‡é™åˆ¶

        else:
            logging.info(f"PMID {article['pmid']} (PMCID: {article['pmcid']}, DOI: {article['doi']}) å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡")

    if new_articles:
        send_email(new_articles)  # åªå‘é€æ–°çš„æ–‡çŒ®
        save_processed_pmids(processed_pmids)  # ä¿å­˜å·²å¤„ç†çš„PMIDåˆ—è¡¨
    else:
        logging.info("âŒ æ²¡æœ‰æ–°çš„æ–‡çŒ®éœ€è¦å‘é€")
