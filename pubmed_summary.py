import os
import time
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from Bio import Entrez
from bs4 import BeautifulSoup
import requests
import logging
import dotenv
import json
from datetime import datetime, timedelta
import openai

# Load environment variables from .env file
dotenv.load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ç¯å¢ƒå˜é‡é…ç½®
PUBMED_API_KEY = os.getenv("PUBMED_API_KEY")
EMAIL_ADDRESS = os.getenv("EMAIL_ADDRESS")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
SMTP_SERVER = os.getenv("EMAIL_SMTP_SERVER", "smtp.yeah.net")
SMTP_PORT = int(os.getenv("EMAIL_SMTP_PORT", 465))
SEARCH_QUERY = os.getenv("SEARCH_QUERY")
MAX_RESULTS = int(os.getenv("MAX_RESULTS", 5))
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")  # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ DEEPSEEK_API_KEY
DEEPSEEK_BASE_URL = "https://api.deepseek.com" # Deepseek API çš„åŸºç¡€ URL
SUMMARY_LANGUAGE = os.getenv("SUMMARY_LANGUAGE", "en")  # å¯ä»¥é…ç½®æ€»ç»“è¯­è¨€
# File to store processed PMIDs
PROCESSED_PMIDS_FILE = os.getenv("PROCESSED_PMIDS_FILE", "processed_pmids.json")
# Expiration time for processed PMIDs (in days)
PROCESSED_PMIDS_EXPIRATION_DAYS = int(os.getenv("PROCESSED_PMIDS_EXPIRATION_DAYS", 30))

# åˆå§‹åŒ–é…ç½®
Entrez.email = EMAIL_ADDRESS
Entrez.api_key = PUBMED_API_KEY

# åˆå§‹åŒ– DeepSeek API å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)


def load_processed_pmids():
    """Load processed PMIDs from file."""
    try:
        with open(PROCESSED_PMIDS_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except json.JSONDecodeError:  # Handle corrupted JSON file
        logging.warning("Processed PMIDs file is corrupted. Starting with an empty list.")
        return []


def save_processed_pmids(pmids):
    """Save processed PMIDs to file."""
    try:
        with open(PROCESSED_PMIDS_FILE, "w") as f:
            json.dump(pmids, f)
    except Exception as e:
        logging.error(f"Failed to save processed PMIDs to file: {e}")


def fetch_articles():
    """è·å–æ–‡çŒ®åˆ—è¡¨"""
    try:
        handle = Entrez.esearch(
            db="pubmed",
            term=SEARCH_QUERY,
            retmax=MAX_RESULTS,
            sort="pub_date",
            usehistory="y"
        )
        result = Entrez.read(handle)
        return result["IdList"]
    except Exception as e:
        logging.error(f"æ–‡çŒ®æœç´¢å¤±è´¥: {str(e)}")  # ä½¿ç”¨logging
        return []


def translate_text(text, target_language="zh-CN"):
    """ä½¿ç”¨ DeepSeek API ç¿»è¯‘æ–‡æœ¬"""
    if not text:
        return ""
    try:
        prompt = f"Translate the following text to {target_language}: {text}"
        response = client.chat.completions.create(
            model="deepseek-chat",  # æˆ–è€…é€‰æ‹©å…¶ä»–é€‚åˆç¿»è¯‘çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in translating scientific articles."},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content.strip() if response.choices else text
    except Exception as e:
        logging.error(f"DeepSeek API ç¿»è¯‘å¤±è´¥: {str(e)}")
        return text


def summarize_text(text, target_language="en"):  # é»˜è®¤è‹±æ–‡æ€»ç»“
    """ä½¿ç”¨ DeepSeek API ç”Ÿæˆæ–‡æœ¬æ€»ç»“"""
    if not text:
        return "æ— å†…å®¹å¯æ€»ç»“"
    try:
        prompt = f"""
        Please provide an academic summary of the following medical research article, 
        ensuring it encompasses the study's objective or background, the methodology used, 
        the principal research results obtained, and an assessment of the research's significance and value. 
        The summary should be clear, concise, and free of unnecessary detail.
        æ–‡æœ¬ï¼š
        {text}
        """
        response = client.chat.completions.create(
            model="deepseek-chat",  # æˆ–è€…é€‰æ‹©å…¶ä»–é€‚åˆæ‘˜è¦çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in summarizing scientific articles."},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        # æ¸…ç† DeepSeek API è¿”å›çš„æ–‡æœ¬
        summary = response.choices[0].message.content.strip() if response.choices else "æ— æ³•ç”Ÿæˆæ€»ç»“"
        cleaned_text = summary.replace("**", "").replace("*", "",).replace("â– ", "").replace("â—", "").replace("â—†", "")
        return cleaned_text
    except Exception as e:
        logging.error(f"DeepSeek API æ€»ç»“å¤±è´¥: {str(e)}")
        return "æ— æ³•ç”Ÿæˆæ€»ç»“"

def get_fulltext_by_doi(doi):
    """å°è¯•é€šè¿‡DOIè·å–å…¨æ–‡"""
    if doi == "æ— DOI":
        return None

    try:
        url = f"https://doi.org/{doi}"
        response = requests.get(url, headers={"Accept": "text/plain"}, timeout=10)
        if response.status_code == 200:
             return response.text
        else:
            print(f"é€šè¿‡DOIè·å–å…¨æ–‡å¤±è´¥ (Status Code: {response.status_code}), doi: {doi}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚DOIå…¨æ–‡å¤±è´¥: {str(e)}, doi: {doi}")
        return None

def get_fulltext_by_pmcid(pmcid):
    """å°è¯•é€šè¿‡PMCIDè·å–å…¨æ–‡"""
    if not pmcid or pmcid == "æ— PMCID":
        return None

    try:
        url = f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmcid}/?format=txt"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
           return response.text
        else:
           print(f"é€šè¿‡PMCIDè·å–å…¨æ–‡å¤±è´¥ (Status Code: {response.status_code}), pmcid: {pmcid}")
           return None
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚PMCIDå…¨æ–‡å¤±è´¥: {str(e)}, pmcid: {pmcid}")
        return None

def get_article_details(pmid):
    """è·å–å•ç¯‡æ–‡çŒ®è¯¦ç»†ä¿¡æ¯"""
    try:
        handle = Entrez.efetch(db="pubmed", id=pmid, rettype="xml", retmode="text")
        xml_data = handle.read()
        soup = BeautifulSoup(xml_data, "lxml-xml")

        # è§£æå…ƒæ•°æ®
        meta = {
            "title": soup.find("ArticleTitle").get_text() if soup.find("ArticleTitle") else "æ— æ ‡é¢˜",
            "journal": soup.find("ISOAbbreviation").get_text() if soup.find("ISOAbbreviation") else "æœªçŸ¥æ‚å¿—",
            "year": soup.find("Year").get_text() if soup.find("Year") else "æœªçŸ¥å¹´ä»½",
            "doi": soup.find("ELocationID", {"EIdType": "doi"}).get_text() if soup.find("ELocationID", {"EIdType": "doi"}) else "æ— DOI",
            "pmcid": soup.find("ArticleId", {"IdType": "pmc"}).get_text() if soup.find("ArticleId", {"IdType": "pmc"}) else "æ— PMCID"
        }

        # å¤„ç†ä½œè€…ä¿¡æ¯
        authors = []
        for author in soup.find_all("Author"):
            lastname = author.find("LastName").get_text() if author.find("LastName") else ""
            initials = author.find("Initials").get_text() if author.find("Initials") else ""
            if lastname and initials:
                authors.append(f"{lastname} {initials}")

        # å¤„ç†æ‘˜è¦
        abstract = ""
        if abstract_section := soup.find("Abstract"):
            abstract = "\n".join([text.get_text() for text in abstract_section.find_all("AbstractText")])

        # è·å–å…¨æ–‡æˆ–ä½¿ç”¨æ‘˜è¦è¿›è¡Œæ€»ç»“
        fulltext = get_fulltext_by_doi(meta["doi"])
        if not fulltext:
            fulltext = get_fulltext_by_pmcid(meta["pmcid"])

        if fulltext:
            summary = summarize_text(fulltext)
        else:
            summary = summarize_text(abstract or "æ— æ‘˜è¦")

        translated_summary = translate_text(summary, target_language="zh-CN")
        translated_title = translate_text(meta["title"], target_language="zh-CN")

        return {
            "pmid": pmid,
            **meta,
            "authors": authors,
            "abstract": abstract,
            "translated_title": translated_title,
            "summary": translated_summary,
            "link": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
        }

    except Exception as e:
        print(f"è·å–æ–‡çŒ® {pmid} è¯¦æƒ…å¤±è´¥: {str(e)}")
        return None

def cleanup_processed_pmids(pmids):
    """Cleanup processed PMIDs, removing entries older than PROCESSED_PMIDS_EXPIRATION_DAYS."""
    cutoff_date = datetime.now() - timedelta(days=PROCESSED_PMIDS_EXPIRATION_DAYS)
    cleaned_pmids = []
    for entry in pmids:
        try:
            # Assuming the timestamp is stored as a string in ISO format
            entry_date = datetime.fromisoformat(entry["timestamp"])
            if entry_date >= cutoff_date:
                cleaned_pmids.append(entry)
        except (KeyError, ValueError) as e:
            logging.warning(f"Invalid entry format in processed PMIDs: {entry}. Error: {e}. Skipping.")
            continue  # Skip invalid entries
    logging.info(f"Cleaned up processed PMIDs, removed {len(pmids) - len(cleaned_pmids)} entries.")
    return cleaned_pmids

def send_email(articles):
    """å‘é€æ–‡çŒ®æ±‡æ€»é‚®ä»¶"""
    try:
        # æ„å»ºé‚®ä»¶å†…å®¹
        msg = MIMEMultipart()
        msg["From"] = EMAIL_ADDRESS
        msg["To"] = EMAIL_ADDRESS
        msg["Subject"] = f"PubMedæ–‡çŒ®æ›´æ–° - {SEARCH_QUERY}"

        # HTMLå†…å®¹æ¨¡æ¿
        html_content = f"""
        <html>
            <body>
                <h2>æœ€æ–° {len(articles)} ç¯‡æ–‡çŒ®</h2>
                <p>æœç´¢å…³é”®è¯: {SEARCH_QUERY}</p>
        """

        for idx, article in enumerate(articles, 1):
            html_content += f"""
            <div style="margin-bottom: 30px; border-bottom: 1px solid #eee;">
                <h3>{idx}. {article['title']}</h3>
                 <p><b>ä¸­æ–‡æ ‡é¢˜:</b> {article['translated_title']}</p>
                <p><b>ä½œè€…:</b> {', '.join(article['authors'])}</p>
                <p><b>æœŸåˆŠ:</b> {article['journal']} ({article['year']})</p>
                <p><b>ä¸­æ–‡æ€»ç»“:</b><br>{article['summary']}</p>
                <p>
                    <a href="{article['link']}">PubMedé“¾æ¥</a> |
                    <a href="https://doi.org/{article['doi']}">å…¨æ–‡é“¾æ¥</a>
                </p>
            </div>
            """

        html_content += "</body></html>"
        msg.attach(MIMEText(html_content, "html", "utf-8"))

        # å‘é€é‚®ä»¶
        try:
            logging.info(f"Connecting to SMTP server: {SMTP_SERVER}:{SMTP_PORT}")
            with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:
                logging.info(f"Logging in to email account: {EMAIL_ADDRESS}")
                server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
                logging.info("Login successful.")
                logging.info(f"Sending email to: {EMAIL_ADDRESS}")
                server.send_message(msg)
                logging.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
        except smtplib.SMTPException as e:
            logging.error(f"âŒ SMTP error occurred: {e}")
            raise  # Re-raise the exception to be caught in the outer block

    except Exception as e:
        logging.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    logging.info("ğŸš€ å¼€å§‹è·å–æ–‡çŒ®...")
    article_ids = fetch_articles()

    if not article_ids:
        logging.warning("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®")  # ä½¿ç”¨logging
        exit()

    processed_pmids = load_processed_pmids()
    # Clean up expired PMIDs before processing
    processed_pmids = cleanup_processed_pmids(processed_pmids)

    new_articles = []

    for pmid in article_ids:
        # Format processed_pmids correctly for checking
        processed_pmids_ids = [entry['pmid'] for entry in processed_pmids]

        if pmid not in processed_pmids_ids:
            try:
                if article := get_article_details(pmid):
                    new_articles.append(article)
                    # Store PMID with timestamp
                    processed_pmids.append({"pmid": pmid, "timestamp": datetime.now().isoformat()})
                time.sleep(0.5)  # é¿å…é€Ÿç‡é™åˆ¶ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
            except Exception as e:
                logging.exception(f"å¤„ç†PMID {pmid} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")  # è®°å½•å®Œæ•´å †æ ˆä¿¡æ¯
        else:
            logging.info(f"PMID {pmid} å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡")

    if new_articles:
        send_email(new_articles)  # åªå‘é€æ–°çš„æ–‡çŒ®
        save_processed_pmids(processed_pmids)  # ä¿å­˜å·²å¤„ç†çš„PMIDåˆ—è¡¨
    else:
        logging.info("âŒ æ²¡æœ‰æ–°çš„æ–‡çŒ®éœ€è¦å‘é€")
